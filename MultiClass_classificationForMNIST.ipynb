{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "import time \n",
    "import sys\n",
    "import math\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# from sklearn.metrics import average_precision\n",
    "from scipy.io import loadmat\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import classification_report\n",
    "import random\n",
    "import sys\n",
    "# from sklearn.metrics import multilabel_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_subsample(x,y,subsample_size):\n",
    "    #subsample_size is the percentage of each class that we would sample\n",
    "    #this way we make sure we have a balanced sample dataset from each class\n",
    "    \n",
    "    class_xs = []\n",
    "    min_elems = None\n",
    "\n",
    "    for yi in np.unique(y):\n",
    "        elems = x[(y == yi)]\n",
    "#         print ('elems',elems)\n",
    "#         print ('yi',yi)\n",
    "#         sys.exit(1)\n",
    "        class_xs.append((yi, elems))\n",
    "        if min_elems == None or elems.shape[0] < min_elems:\n",
    "            min_elems = elems.shape[0]\n",
    "\n",
    "    use_elems = min_elems\n",
    "    if subsample_size < 1:\n",
    "        use_elems = int(min_elems*subsample_size)\n",
    "\n",
    "    xs = []\n",
    "    ys = []\n",
    "\n",
    "    for ci,this_xs in class_xs:\n",
    "        if len(this_xs) > use_elems:\n",
    "            np.random.shuffle(this_xs)\n",
    "\n",
    "        x_ = this_xs[:use_elems]\n",
    "        y_ = np.empty(use_elems)\n",
    "        y_.fill(ci)\n",
    "\n",
    "        xs.append(x_)\n",
    "        ys.append(y_)\n",
    "\n",
    "    xs = np.concatenate(xs)\n",
    "    ys = np.concatenate(ys)\n",
    "\n",
    "    return xs,ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest = loadmat('mnist_10digits.mat')['xtest'][:]\n",
    "Xtrain = loadmat('mnist_10digits.mat')['xtrain'][:]\n",
    "Ytest = loadmat('mnist_10digits.mat')['ytest'][0]\n",
    "Ytrain = loadmat('mnist_10digits.mat')['ytrain'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standardize features between 0 - 1\n",
    "std_Xtrain = Xtrain/255.0\n",
    "std_Xtest = Xtest/255.0\n",
    "std_Ytrain = Ytrain\n",
    "std_Ytest = Ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resample data for SVM\n",
    "x_train, y_train = take_subsample(std_Xtrain,std_Ytrain,0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unoptimized model\n",
      "------\n",
      "f1  score on testing data: [0.97840281 0.97588286 0.9710926  0.96538081 0.9687019  0.96582633\n",
      " 0.98386257 0.96108949 0.96206533 0.95483871]\n",
      "\n",
      "Optimized Model\n",
      "------\n",
      "Final f1 score on the testing data: [0.979428   0.97546276 0.97067449 0.96500739 0.96846389 0.96259073\n",
      " 0.98329854 0.95782841 0.95906433 0.95883534]\n",
      "Final precision score on the testing data: [0.96347483 0.9537037  0.97928994 0.96074583 0.96747967 0.95884316\n",
      " 0.98329854 0.95458937 0.99448732 0.97151577]\n",
      "Final recall score on the testing data: [0.99591837 0.99823789 0.9622093  0.96930693 0.9694501  0.96636771\n",
      " 0.98329854 0.96108949 0.92607803 0.94648167]\n",
      "confusion matrix: \n",
      "[[ 969    0    2    2    0    4    1    1    1    0]\n",
      " [   0 1122    3    2    0    1    3    1    3    0]\n",
      " [   6    0  991    5    6    0    5    8   11    0]\n",
      " [   0    0    5  968    0   12    0   10   12    3]\n",
      " [   1    1    4    0  951    0    7    2    1   15]\n",
      " [   5    1    2   14    2  851    6    1    7    3]\n",
      " [   8    3    1    1    2    7  933    0    3    0]\n",
      " [   0   12   21    2    4    0    0  967    3   19]\n",
      " [   5    0    6    8    7   10    7    6  923    2]\n",
      " [   6    5    3    8   23    6    0    8    3  947]]\n",
      "parameters <bound method KNeighborsClassifier.get_params of KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=None, n_neighbors=4, p=2,\n",
      "           weights='uniform')>\n"
     ]
    }
   ],
   "source": [
    "# determine the optimum number of neighbors in KNN and get the best classification\n",
    "\n",
    "clf = KNeighborsClassifier()\n",
    "\n",
    "# Create the parameters list you wish to tune\n",
    "parameters = {'n_neighbors' : [2,4,8,10,20]}\n",
    "\n",
    "# Make an fbeta_score scoring object\n",
    "scorer = make_scorer(f1_score,average='weighted')\n",
    "\n",
    "# Perform grid search on the classifier using 'scorer' as the scoring method\n",
    "grid_obj = GridSearchCV(clf, parameters, scoring=scorer)\n",
    "\n",
    "# Fit the grid search object to the training data and find the optimal parameters\n",
    "grid_fit = grid_obj.fit(std_Xtrain, std_Ytrain)\n",
    "\n",
    "# Get the estimator\n",
    "best_clf = grid_fit.best_estimator_\n",
    "\n",
    "# Make predictions using the unoptimized and model\n",
    "predictions = (clf.fit(std_Xtrain, std_Ytrain)).predict(std_Xtest)\n",
    "best_predictions = best_clf.predict(std_Xtest)\n",
    "\n",
    "# Report the before-and-afterscores\n",
    "print (\"Unoptimized model\\n------\")\n",
    "print ('f1  score on testing data: ' + str(f1_score(std_Ytest, predictions,average = None)))\n",
    "print (\"\\nOptimized Model\\n------\")\n",
    "print (\"Final f1 score on the testing data: \"+ str(f1_score(std_Ytest, best_predictions,average = None)))\n",
    "print (\"Final precision score on the testing data: \"+str(precision_score(std_Ytest, best_predictions,average = None)))\n",
    "print (\"Final recall score on the testing data: \"+str(recall_score(std_Ytest, best_predictions,average = None)))\n",
    "print (\"confusion matrix: \")\n",
    "print (confusion_matrix(std_Ytest, svm_clf.predict(std_Xtest)))\n",
    "\n",
    "print \"parameters\", best_clf.get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix for K nearest neighbor is:  [[ 975    1    1    0    0    1    1    1    0    0]\n",
      " [   0 1132    2    0    0    0    1    0    0    0]\n",
      " [  24   20  955    3    2    0    3   19    6    0]\n",
      " [   1    4    4  970    1   14    0    6    6    4]\n",
      " [   0   17    1    0  936    0    3    0    1   24]\n",
      " [   6    2    0   28    3  838    7    1    2    5]\n",
      " [  10    4    0    0    3    5  936    0    0    0]\n",
      " [   0   32    3    0    6    1    0  975    0   11]\n",
      " [  10    3    4   25    7   34    5   10  870    6]\n",
      " [   9    7    3    6   12    6    1   19    1  945]]\n",
      "precision for K nearest neighbor is:  0.9539728846464691  recall:  0.9532  f1 score:  0.9530565279426535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97       980\n",
      "           1       0.99      0.97      0.98      1135\n",
      "           2       0.95      0.96      0.96      1032\n",
      "           3       0.93      0.95      0.94      1010\n",
      "           4       0.96      0.94      0.95       982\n",
      "           5       0.94      0.94      0.94       892\n",
      "           6       0.96      0.96      0.96       958\n",
      "           7       0.96      0.95      0.95      1028\n",
      "           8       0.93      0.94      0.93       974\n",
      "           9       0.95      0.95      0.95      1009\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#calculate SVM results with Gamma based on Median Trick\n",
    "\n",
    "KNN = KNeighborsClassifier(n_neighbors=4)\n",
    "KNN_clf = KNN.fit(x_train, y_train)\n",
    "\n",
    "KNN_mat = confusion_matrix(std_Ytest, KNN_clf.predict(std_Xtest))\n",
    "KNN_precision = precision_score(std_Ytest, KNN_clf.predict(std_Xtest),average='weighted')\n",
    "KNN_recall = recall_score(std_Ytest, KNN_clf.predict(std_Xtest),average='weighted')\n",
    "KNN_f1 = f1_score(std_Ytest, KNN_clf.predict(std_Xtest),average='weighted')\n",
    "\n",
    "print \"confusion matrix for K nearest neighbor is: \", KNN_mat\n",
    "print \"precision for K nearest neighbor is: \", KNN_precision, \" recall: \", KNN_recall, \" f1 score: \", KNN_f1\n",
    "print (classification_report(Ytest, KNN_clf.predict(std_Xtest), labels=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate Gamma for SVM using Median trick\n",
    "temp_distance= np.zeros(1000)\n",
    "\n",
    "for k in range(1000):\n",
    "    i  = random.randint(1, (x_train.shape[0]-1))\n",
    "    \n",
    "    j = random.randint(1, (x_train.shape[0]-1))\n",
    "    if i==j:\n",
    "        while i==j:\n",
    "            j = random.ranint(1, x_train.shape[0]) \n",
    "    temp_distance[k] = sum(np.power((x_train[i,:] - x_train[j,:] ),2))\n",
    "\n",
    "m = np.median(temp_distance)\n",
    "sigma = (m/2.0)**0.5\n",
    "Gamma = 0.5/(sigma**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix for kernel SVM is:  [[ 969    0    2    2    0    4    1    1    1    0]\n",
      " [   0 1122    3    2    0    1    3    1    3    0]\n",
      " [   6    0  991    5    6    0    5    8   11    0]\n",
      " [   0    0    5  968    0   12    0   10   12    3]\n",
      " [   1    1    4    0  951    0    7    2    1   15]\n",
      " [   5    1    2   14    2  851    6    1    7    3]\n",
      " [   8    3    1    1    2    7  933    0    3    0]\n",
      " [   0   12   21    2    4    0    0  967    3   19]\n",
      " [   5    0    6    8    7   10    7    6  923    2]\n",
      " [   6    5    3    8   23    6    0    8    3  947]]\n",
      "precision for kernel SVM is:  0.9621663000557678  recall:  0.9622  f1 score:  0.9621418323782506\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       980\n",
      "           1       0.98      0.99      0.98      1135\n",
      "           2       0.95      0.96      0.96      1032\n",
      "           3       0.96      0.96      0.96      1010\n",
      "           4       0.96      0.97      0.96       982\n",
      "           5       0.96      0.95      0.95       892\n",
      "           6       0.97      0.97      0.97       958\n",
      "           7       0.96      0.94      0.95      1028\n",
      "           8       0.95      0.95      0.95       974\n",
      "           9       0.96      0.94      0.95      1009\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     10000\n",
      "   macro avg       0.96      0.96      0.96     10000\n",
      "weighted avg       0.96      0.96      0.96     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#calculate SVM results with Gamma based on Median Trick\n",
    "\n",
    "SVM = svm.SVC(kernel='rbf',gamma=Gamma)\n",
    "svm_clf = SVM.fit(x_train, y_train)\n",
    "\n",
    "SVM_mat = confusion_matrix(std_Ytest, svm_clf.predict(std_Xtest))\n",
    "SVM_precision = precision_score(std_Ytest, svm_clf.predict(std_Xtest),average='weighted')\n",
    "SVM_recall = recall_score(std_Ytest, svm_clf.predict(std_Xtest),average='weighted')\n",
    "SVM_f1 = f1_score(std_Ytest, svm_clf.predict(std_Xtest),average='weighted')\n",
    "\n",
    "print \"confusion matrix for kernel SVM is: \", SVM_mat\n",
    "print \"precision for kernel SVM is: \", SVM_precision, \" recall: \", SVM_recall, \" f1 score: \", SVM_f1\n",
    "print (classification_report(Ytest, svm_clf.predict(std_Xtest), labels=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix for SVM is:  [[ 959    0    0    3    1    9    7    0    1    0]\n",
      " [   0 1115    3    2    0    2    2    1   10    0]\n",
      " [  12    2  952   17    8    5    7   11   18    0]\n",
      " [   4    2   18  938    1   22    0    5   14    6]\n",
      " [   2    1   11    0  927    0   11    5    1   24]\n",
      " [  14    3    5   50    6  772   12    3   21    6]\n",
      " [   7    4   12    2    9   13  906    2    3    0]\n",
      " [   0   11   20    6    7    0    0  950    0   34]\n",
      " [  14    2   16   24   13   25   10    8  854    8]\n",
      " [   5    6    8    9   45   10    1   25    5  895]]\n",
      "precision for SVM is:  0.9267901208852755  recall:  0.9268  f1 score:  0.9265712338684554\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96       980\n",
      "           1       0.97      0.98      0.98      1135\n",
      "           2       0.91      0.92      0.92      1032\n",
      "           3       0.89      0.93      0.91      1010\n",
      "           4       0.91      0.94      0.93       982\n",
      "           5       0.90      0.87      0.88       892\n",
      "           6       0.95      0.95      0.95       958\n",
      "           7       0.94      0.92      0.93      1028\n",
      "           8       0.92      0.88      0.90       974\n",
      "           9       0.92      0.89      0.90      1009\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     10000\n",
      "   macro avg       0.93      0.93      0.93     10000\n",
      "weighted avg       0.93      0.93      0.93     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#linear SVM\n",
    "SVM = svm.SVC(kernel='linear')\n",
    "svm_clf = SVM.fit(x_train, y_train)\n",
    "\n",
    "SVM_mat = confusion_matrix(Ytest, svm_clf.predict(std_Xtest))\n",
    "SVM_precision = precision_score(Ytest, svm_clf.predict(std_Xtest),average='weighted')\n",
    "SVM_recall = recall_score(Ytest, svm_clf.predict(std_Xtest),average='weighted')\n",
    "SVM_f1 = f1_score(Ytest, svm_clf.predict(std_Xtest),average='weighted')\n",
    "\n",
    "print \"confusion matrix for SVM is: \", SVM_mat\n",
    "print \"precision for SVM is: \", SVM_precision, \" recall: \", SVM_recall, \" f1 score: \", SVM_f1\n",
    "print (classification_report(Ytest, svm_clf.predict(std_Xtest), labels=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shahrzad\\Anaconda2\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Shahrzad\\Anaconda2\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unoptimized model\n",
      "------\n",
      "f1  score on testing data: 0.9199\n",
      "\n",
      "Optimized Model\n",
      "------\n",
      "Final f1 score on the testing data: 0.9196\n",
      "Final precision score on the testing data: 0.9196\n",
      "Final recall score on the testing data: 0.9198\n",
      "confusion matrix: \n",
      "[[265   0   0   0   0   1   0   0   1   0]\n",
      " [  0 264   1   1   0   0   0   1   0   0]\n",
      " [  1   0 256   3   2   0   1   1   3   0]\n",
      " [  0   0   1 257   0   4   0   1   2   2]\n",
      " [  0   0   0   0 258   0   3   0   0   6]\n",
      " [  0   0   1   2   0 261   1   0   2   0]\n",
      " [  4   1   1   0   3   3 255   0   0   0]\n",
      " [  1   0   6   1   1   0   0 258   0   0]\n",
      " [  0   1   2   3   0   4   2   0 254   1]\n",
      " [  1   2   0   5   5   2   0   2   3 247]]\n",
      "parameters <bound method LogisticRegression.get_params of LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
      "          n_jobs=None, penalty='l2', random_state=0, solver='saga',\n",
      "          tol=0.0001, verbose=0, warm_start=False)>\n"
     ]
    }
   ],
   "source": [
    "#determine the best hyperparameters for Logistics regression\n",
    "\n",
    "clf = LogisticRegression(random_state=0)\n",
    "\n",
    "# Create the parameters list you wish to tune\n",
    "parameters = {'C':[100, 10, 1.0, 0.1, 0.01],\n",
    "              'solver':['newton-cg', 'lbfgs', 'sag', 'saga']}\n",
    "\n",
    "\n",
    "# Make an fbeta_score scoring object\n",
    "scorer = make_scorer(f1_score,average='weighted')\n",
    "\n",
    "# Perform grid search on the classifier using 'scorer' as the scoring method\n",
    "grid_obj = GridSearchCV(clf, parameters, scoring=scorer)\n",
    "\n",
    "# Fit the grid search object to the training data and find the optimal parameters\n",
    "grid_fit = grid_obj.fit(std_Xtrain, std_Ytrain)\n",
    "\n",
    "# Get the estimator\n",
    "best_clf = grid_fit.best_estimator_\n",
    "\n",
    "# Make predictions using the unoptimized and model\n",
    "predictions = (clf.fit(std_Xtrain, std_Ytrain)).predict(std_Xtest)\n",
    "best_predictions = best_clf.predict(std_Xtest)\n",
    "\n",
    "# Report the before-and-afterscores\n",
    "print \"Unoptimized model\\n------\"\n",
    "print \"f1  score on testing data: {:.4f}\".format(f1_score(std_Ytest, predictions,average='weighted'))\n",
    "print \"\\nOptimized Model\\n------\"\n",
    "print \"Final f1 score on the testing data: {:.4f}\".format(f1_score(std_Ytest, best_predictions,average='weighted'))\n",
    "print \"Final precision score on the testing data: {:.4f}\".format(precision_score(std_Ytest, best_predictions,average='weighted'))\n",
    "print \"Final recall score on the testing data: {:.4f}\".format(recall_score(std_Ytest, best_predictions,average='weighted'))\n",
    "print \"confusion matrix: \"\n",
    "print (confusion_matrix(y_test, svm_clf.predict(x_test)))\n",
    "\n",
    "print \"parameters\", best_clf.get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix for logistics regression is:  [[ 960    0    1    2    0    5    6    3    1    2]\n",
      " [   0 1112    3    1    0    1    5    1   12    0]\n",
      " [   8    8  920   20    9    5   10   11   37    4]\n",
      " [   4    0   17  919    2   22    4   12   21    9]\n",
      " [   1    2    5    3  914    0   10    2    7   38]\n",
      " [  10    2    0   42   10  769   17    7   28    7]\n",
      " [   9    3    7    2    6   20  907    1    3    0]\n",
      " [   2    7   22    5    8    1    1  950    5   27]\n",
      " [  10   14    5   21   14   27    7   11  853   12]\n",
      " [   8    8    2   13   31   14    0   24   12  897]]\n",
      "precision for logistics regression is:  0.919956947795481  recall:  0.9201  f1 score:  0.919899218277874\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.96       980\n",
      "           1       0.96      0.98      0.97      1135\n",
      "           2       0.94      0.89      0.91      1032\n",
      "           3       0.89      0.91      0.90      1010\n",
      "           4       0.92      0.93      0.93       982\n",
      "           5       0.89      0.86      0.88       892\n",
      "           6       0.94      0.95      0.94       958\n",
      "           7       0.93      0.92      0.93      1028\n",
      "           8       0.87      0.88      0.87       974\n",
      "           9       0.90      0.89      0.89      1009\n",
      "\n",
      "   micro avg       0.92      0.92      0.92     10000\n",
      "   macro avg       0.92      0.92      0.92     10000\n",
      "weighted avg       0.92      0.92      0.92     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#logistics regression with default values\n",
    "\n",
    "logReg = LogisticRegression(random_state=0).fit(std_Xtrain, Ytrain)\n",
    "logReg_mat = confusion_matrix(Ytest, logReg.predict(std_Xtest))\n",
    "logReg_precision = precision_score(Ytest, logReg.predict(std_Xtest),average='weighted')\n",
    "logReg_recall = recall_score(Ytest, logReg.predict(std_Xtest),average='weighted')\n",
    "logReg_f1 = f1_score(Ytest, logReg.predict(std_Xtest),average='weighted')\n",
    "\n",
    "print \"confusion matrix for logistics regression is: \", logReg_mat\n",
    "print \"precision for logistics regression is: \", logReg_precision, \" recall: \", logReg_recall, \" f1 score: \", logReg_f1\n",
    "print (classification_report(Ytest, logReg.predict(std_Xtest), labels=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unoptimized model\n",
      "------\n",
      "f1  score on testing data: 0.9513\n",
      "\n",
      "Optimized Model\n",
      "------\n",
      "Final f1 score on the testing data: 0.9587\n",
      "Final precision score on the testing data: 0.9589\n",
      "Final recall score on the testing data: 0.9587\n",
      "confusion matrix: \n",
      "[[265   0   0   0   0   1   0   0   1   0]\n",
      " [  0 264   1   1   0   0   0   1   0   0]\n",
      " [  1   0 256   3   2   0   1   1   3   0]\n",
      " [  0   0   1 257   0   4   0   1   2   2]\n",
      " [  0   0   0   0 258   0   3   0   0   6]\n",
      " [  0   0   1   2   0 261   1   0   2   0]\n",
      " [  4   1   1   0   3   3 255   0   0   0]\n",
      " [  1   0   6   1   1   0   0 258   0   0]\n",
      " [  0   1   2   3   0   4   2   0 254   1]\n",
      " [  1   2   0   5   5   2   0   2   3 247]]\n",
      "parameters <bound method MLPClassifier.get_params of MLPClassifier(activation='relu', alpha=0.05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(20, 10), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False)>\n"
     ]
    }
   ],
   "source": [
    "#determine the best hyperparameters for MLPClassifier\n",
    "\n",
    "clf = MLPClassifier(hidden_layer_sizes=(20,10))\n",
    "\n",
    "# Create the parameters list you wish to tune\n",
    "parameters = {'solver' :[ 'sgd', 'adam'],\n",
    "              'activation': ['tanh', 'relu'],\n",
    "              'alpha': [0.0001, 0.05]}\n",
    "\n",
    "\n",
    "# Make an fbeta_score scoring object\n",
    "scorer = make_scorer(f1_score,average='weighted')\n",
    "\n",
    "# Perform grid search on the classifier using 'scorer' as the scoring method\n",
    "grid_obj = GridSearchCV(clf, parameters, scoring=scorer)\n",
    "\n",
    "# Fit the grid search object to the training data and find the optimal parameters\n",
    "grid_fit = grid_obj.fit(std_Xtrain, std_Ytrain)\n",
    "\n",
    "# Get the estimator\n",
    "best_clf = grid_fit.best_estimator_\n",
    "\n",
    "# Make predictions using the unoptimized and model\n",
    "predictions = (clf.fit(std_Xtrain, std_Ytrain)).predict(std_Xtest)\n",
    "best_predictions = best_clf.predict(std_Xtest)\n",
    "\n",
    "# Report the before-and-afterscores\n",
    "print \"Unoptimized model\\n------\"\n",
    "print \"f1  score on testing data: {:.4f}\".format(f1_score(std_Ytest, predictions,average='weighted'))\n",
    "print \"\\nOptimized Model\\n------\"\n",
    "print \"Final f1 score on the testing data: {:.4f}\".format(f1_score(std_Ytest, best_predictions,average='weighted'))\n",
    "print \"Final precision score on the testing data: {:.4f}\".format(precision_score(std_Ytest, best_predictions,average='weighted'))\n",
    "print \"Final recall score on the testing data: {:.4f}\".format(recall_score(std_Ytest, best_predictions,average='weighted'))\n",
    "print \"confusion matrix: \"\n",
    "print (confusion_matrix(y_test, svm_clf.predict(x_test)))\n",
    "\n",
    "print \"parameters\", best_clf.get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix for Neural networks is:  [[ 957    1    2    0    4    3    5    1    1    6]\n",
      " [   0 1114    4    2    1    2    3    3    6    0]\n",
      " [   3    6  976   13    6    2    2   10   14    0]\n",
      " [   5    4    8  948    0   12    0   14   12    7]\n",
      " [   2    0    5    1  911    3   23    9    3   25]\n",
      " [   5    2    0   18    6  828   11    1   11   10]\n",
      " [   8    3    8    0    7   11  911    1    9    0]\n",
      " [   3    4   12    4    6    0    0  975   10   14]\n",
      " [   5    1    5   11    7   10   11    6  909    9]\n",
      " [   5    3    0    6   19    7    1   15    4  949]]\n",
      "precision for Neural networks is:  0.9478017330604122  recall:  0.9478  f1 score:  0.9477749087903768\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97       980\n",
      "           1       0.98      0.98      0.98      1135\n",
      "           2       0.96      0.95      0.95      1032\n",
      "           3       0.95      0.94      0.94      1010\n",
      "           4       0.94      0.93      0.93       982\n",
      "           5       0.94      0.93      0.94       892\n",
      "           6       0.94      0.95      0.95       958\n",
      "           7       0.94      0.95      0.95      1028\n",
      "           8       0.93      0.93      0.93       974\n",
      "           9       0.93      0.94      0.94      1009\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10000\n",
      "   macro avg       0.95      0.95      0.95     10000\n",
      "weighted avg       0.95      0.95      0.95     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Neural networks with default values\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(20,10))\n",
    "M = mlp.fit(std_Xtrain,Ytrain)\n",
    "\n",
    "M_mat = confusion_matrix(Ytest, M.predict(std_Xtest))\n",
    "M_precision = precision_score(Ytest, M.predict(std_Xtest),average='weighted')\n",
    "M_recall = recall_score(Ytest, M.predict(std_Xtest),average='weighted')\n",
    "M_f1 = f1_score(Ytest, M.predict(std_Xtest),average='weighted')\n",
    "\n",
    "print \"confusion matrix for Neural networks is: \", M_mat\n",
    "print \"precision for Neural networks is: \", M_precision, \" recall: \", M_recall, \" f1 score: \", M_f1\n",
    "\n",
    "print (classification_report(Ytest, M.predict(std_Xtest), labels=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
